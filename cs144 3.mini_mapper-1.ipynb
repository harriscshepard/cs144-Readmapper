{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px;border-width:2;color:gray;background-color:#000000\"> \n",
    "<center><h1>CS 144 - Spring 2022 - Mini-Mapping Tool</h1></center>\n",
    "<center><h1>Due: Sunday, June 5th, 2022 @ 11:59pm</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter your information below:\n",
    "\n",
    "<div style=\"color: #000000;background-color: #EEEEFF\">\n",
    "    Your Name (submitter): Harris Shepard <br>\n",
    "    Your student ID (submitter): 862132345\n",
    "    \n",
    "<br>\n",
    "<br>\n",
    "<b>By submitting this notebook, I assert that the work below is my own work, completed for this course.  Except where explicitly cited, none of the portions of this notebook are duplicated from anyone else's work or my own previous work.</b>\n",
    "<br>    \n",
    "<br>\n",
    "<b>Instruction for submissions:</B> when you have completed this project, download this .ipynb file to your computer by left-clicking on the file name, and submit to <a href=\"https://elearn.ucr.edu/\">Canvas</A> by the deadline. \n",
    "<br>\n",
    "<br>\n",
    "<B>Late work:</B> There is no late deadline for the final project, except for the most serious circumstances (illness, medical emergency, etc.) which have to be documented.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px;border-width:2;color:gray;background-color:#000000\"> \n",
    "<center><h1>Generator</h1></center>\n",
    "<br>\n",
    "\n",
    "In the first part of this project, you will write a <B>read generator</B>, that takes in input \n",
    "<UL>\n",
    "<LI>a reference genome $R$ in <A HREF=\"https://blast.ncbi.nlm.nih.gov/Blast.cgi?CMD=Web&PAGE_TYPE=BlastDocs&DOC_TYPE=BlastHelp\">FASTA</A> format (for instance <A HREF=\"http://www.cs.ucr.edu/~stelo/cs144spring22/data/BD.fa\">the BD genome</A>)</LI>\n",
    "    <LI>integer parameter $N$ </LI>\n",
    "    <li>integer parameter $L$ </LI>\n",
    "</UL>\n",
    "and generates a new file in FASTA format containing $N$ reads composed of exactly $L$ symbols obtained by sampling the genome $R$ at random positions. For instance if $N=100000$ and $L=100$, the generator will produce a FASTA file containing 100 thousand reads from random positions in the genome, each of which is 100 nucleotides long. \n",
    "    \n",
    "The FASTA headers should contain the original genomic position of each read so the mapper can verify that the correctness of the positions. For instance\n",
    "\n",
    "&gt;R1 1,1043<br>\n",
    "ACTTACTTTACTATTCATTCTACATTCTA<br>\n",
    "&gt;R2 3,54654<br>\n",
    "TATTTATTTCTCTTATCTATCTATCTATA<br>\n",
    "\n",
    "is a FASTA file with two reads named R1 and R2. R1 originates from position 1043 and R2 originate from position 54654 in the genome $R$.\n",
    "    \n",
    "You are allowed to use Biopython to read and write FASTA files. It is mandatory to acknowledge sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview:\n",
    "This is the minimapper project using a custom FM-index to search. It is not efficient but it works. It is probably worse than using a sliding window.\n",
    "\n",
    "Limitations:\n",
    "time, takes a long time to find patterns\n",
    "exactness, can only find exact matches\n",
    "memory, cannot get all rotations of an entire contig without running out of memory\n",
    "&nbsp;    gets rotations in chunks as a workaround\n",
    "\n",
    "\n",
    "Conclusions and Time Complexity:\n",
    "\n",
    "Reader: time scales primarily with number of patterns\n",
    "    1000 patterns: 35s  \n",
    "    10000 patterns: ~350s\n",
    "    \n",
    "\n",
    "Mapper: time scales primarily with the number of patterns  \n",
    "    1 pattern= 27s for 1.4 million bp worth of bwt = 135s for the entire bd genome with 1 pattern to match  \n",
    "    +50 patterns gives +50s of runtime (50 patterns -> 79s runtime for 1.4 mil bp)  \n",
    "    another +50 gives +56s of runtime (100 patterns -> 135s runtime for 1.4 mil bp)  \n",
    "    +900 gives +993s of runtime (1000 patterns -> 1128s runtime for 1.4 mil bp)      \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total length:  7362482\n",
      "total length valid: 7361582\n",
      "cumulative contig positions: \n",
      "contig1 0 0\n",
      "contig2 1434593 1434493\n",
      "contig3 2502290 2502090\n",
      "contig4 3449599 3449299\n",
      "contig5 4311925 4311525\n",
      "contig6 5170737 5170237\n",
      "contig7 5935667 5935067\n",
      "contig8 6576258 6575558\n",
      "contig9 7017637 7016837\n",
      "<class 'Bio.File._IndexedSeqFileDict'>\n",
      "ID: contig1\n",
      "Name: contig1\n",
      "Description: contig1\n",
      "Number of features: 0\n",
      "Seq('CCAGACTTGCCCTCCAATTGATACTCTGGAAGGGGTTTGGATTCCCATCATTCC...ATG')\n",
      "execution time:  34.490427017211914\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#PURPOSE:\n",
    "#35s for 1000\n",
    "#~350s for 10000\n",
    "#~3500s ~= 1hr for 100,000\n",
    "#Notes:\n",
    "    #Sampled without replacement, no repeats\n",
    "    #Contigs sometimes change ranges???\n",
    "\n",
    "from Bio import SeqIO as seq\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "#random amongst the entire genome\n",
    "#equivalent to random amongst a combination of all records in the fasta file\n",
    "#create record index\n",
    "#using https://biopython.org/wiki/SeqIO\n",
    "\n",
    "start = time()\n",
    "'''>NW_015449929.1 Tetranychus\n",
    "urticae unplaced genomic scaffold, ASM23943v1 scaffold_223, whole genome shotgun sequence\"'''\n",
    "\n",
    "N = 1000\n",
    "L = 100\n",
    "\n",
    "\n",
    "samples = []\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "#Getting indexes or ranges for the contigs\n",
    "#record_pos_index, the absolute cumulative length of each contig\n",
    "#starts_pos_index, the absolute cumulative length of each valid start in each contig\n",
    "#valid start, places where a read can start and not go out of index\n",
    "\n",
    "\n",
    "#fasta_file = seq.parse(\"./minimapper/BD.fasta\", \"fasta\")\n",
    "#fasta_index = seq.index(\"./minimapper/BD.fasta\", \"fasta\")\n",
    "fasta_index = seq.index(\"./BD.fasta\", \"fasta\")\n",
    "\n",
    "start_i = 0\n",
    "start_i_valid = 0\n",
    "record_pos_index = [] #stores an array of genome_position,record_id pairs as an index\n",
    "starts_pos_index = [] #range of valid starts\n",
    "\n",
    "                \n",
    "for record_id in fasta_index: \n",
    "    #print(\"index record: \",record_id)\n",
    "    end_i = start_i+(len(fasta_index[record_id])-1) #99, total contig range\n",
    "    record_pos_index.append((record_id,start_i))\n",
    "\n",
    "    end_i_valid = start_i_valid+(len(fasta_index[record_id])-L-1)\n",
    "    starts_pos_index.append((record_id,start_i_valid))\n",
    "\n",
    "    start_i_valid = end_i_valid +1\n",
    "    start_i = end_i+1\n",
    "\n",
    "\n",
    "valid_end = start_i_valid #set the end of the last contig, exclusive\n",
    "fasta_length = start_i \n",
    "print(\"total length: \", fasta_length)\n",
    "print(\"total length valid:\",valid_end)\n",
    "#print(\"record_position index: \", record_pos_index)\n",
    "print(\"cumulative contig positions: \")\n",
    "for ((record_id,genome_pos),(record_id,valid_start_pos)) in zip(record_pos_index,starts_pos_index):\n",
    "    print(record_id,genome_pos,valid_start_pos)\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "#Sampling random reads and reading from the fasta_index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "random_reads = (random.sample(range(valid_end),N))\n",
    "#NOT SORTING RANDOM reads, defeats purpose, takes too long\n",
    "random_reads.sort() #sorting, group reads by contig\n",
    "#print(\"random reads: \",random_reads)\n",
    "\n",
    "#position_difference, the position relative to the start of the contig\n",
    "#starts_pos_index, indexes of the valid starts for each contig\n",
    "def get_read(random_read, fasta_index,record_pos_index,starts_pos_index):\n",
    "    \n",
    "    #random_read = 7016837\n",
    "    i = 0\n",
    "    for record_id,index in starts_pos_index:\n",
    "        if random_read-index < 0:\n",
    "            break\n",
    "        i+=1\n",
    "    i-=1#went too far\n",
    "        #read is in previous index\n",
    "    position_difference = random_read-starts_pos_index[i][1]\n",
    "\n",
    "    #print(\"found in start_pos index i\",i)\n",
    "    #print(\"position difference\",position_difference)\n",
    "\n",
    "    record_id = record_pos_index[i][0] #start from the absolute position\n",
    "    seq = (fasta_index[record_id].seq)\n",
    "    read = \">\" + record_id+ \",\"+ str(position_difference)+'\\n'+str(seq[position_difference:position_difference+L])+'\\n'\n",
    "    return (read)\n",
    "\n",
    "\n",
    "file = open(\"cs144part1_1000.txt\", \"w\") \n",
    "for read in random_reads:\n",
    "    temp = get_read(read,fasta_index,record_pos_index,starts_pos_index)\n",
    "    file.write(temp)\n",
    "file.close()\n",
    "\n",
    "\n",
    "#get a read\n",
    "record_id = record_pos_index[0][0] #start from the absolute position\n",
    "sequence = (fasta_index[record_id].seq)\n",
    "file = open(\"cs144input.txt\",\"w\")\n",
    "length = 10000\n",
    "file.write(str(sequence[:length]))\n",
    "file.close()\n",
    "\n",
    "#first_record = repr(next(genome)\n",
    "print(type(fasta_index))\n",
    "\n",
    "print((fasta_index[\"contig1\"]))\n",
    "\n",
    "\n",
    "record_id = \"contig\"+str(1)\n",
    "\n",
    "'''\n",
    "for record in fasta_file:\n",
    "    print(len(record)) #length of record\n",
    "    end_i = start_i+(len(record)-1) #99\n",
    "    record_iarr.append(end_i)\n",
    "    start_i = end_i+1 #100\n",
    "    \n",
    "    \n",
    "    print(\"record id \",record.id) #id of record\n",
    "    print(\"record desc\",record.description)\n",
    "    print(repr(record.seq)) #sequence of record, small snippet\n",
    "    #print(\"100,000th pos \", str(record.seq)[100000:100010])\n",
    "    #print(dir(type(record))) #functions in the seqrecords class\n",
    "'''\n",
    "\n",
    "print(\"execution time: \", time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:5px;border-width:2;color:gray;background-color:#000000\"> \n",
    "<center><h1>Mapper</h1></center>\n",
    "<br>\n",
    "\n",
    "In the second part, you will write a <B>read mapper</B>, that takes in input\n",
    "<UL>\n",
    "<LI>a reference genome $R$ in FASTA format</LI>\n",
    "<LI>a set $S$ of reads in FASTA format (generated by the generator)</LI>\n",
    "</UL>\n",
    "The read mapper finds the position(s) of each read in $S$ in the genome $R$, and counts how many are mapped correctly by comparing them to the original position stored in the FASTA header. You can use the original position stored in the FASTA headers <B>only</B> to verify the correctness. \n",
    "\n",
    "You are allowed to use any Python package that implements any of the data structures we saw in class (suffix arrays, suffix trees, FM-index (BWT), or hash tables, etc). You should be able install packages using `!pip install package`. It is mandatory to acknowledge sources.\n",
    "\n",
    "Collect experimental results on time spent by the mapper for several choices of $|R|$ (genome size) and $N$. You can keep $L$ fixed at 100. Is the time linear in $|R|$, or is it super-linear? Is the time linear in $N$ or is it super-linear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing BWT from https://python.algorithms-library.com/compression/burrows_wheeler\n",
    "\n",
    "#Can ignore this file, just for reference for BWT\n",
    "#reused some of the BWT code in the block below\n",
    "\n",
    "#Other considerations:\n",
    "#bowtie and bowtie2, not compatible with windows, required linux virtual machine\n",
    "#linear suffix array, ukkonen's algorithm, could not find a library online\n",
    "\n",
    "\n",
    "#def all_rotations(s: str) -> list[str]:\n",
    "def all_rotations(s: str):\n",
    "    \"\"\"\n",
    "    :param s: The string that will be rotated len(s) times.\n",
    "    :return: A list with the rotations.\n",
    "    :raises TypeError: If s is not an instance of str.\n",
    "    Examples:\n",
    "\n",
    "    >>> all_rotations(\"^BANANA|\") # doctest: +NORMALIZE_WHITESPACE\n",
    "    ['^BANANA|', 'BANANA|^', 'ANANA|^B', 'NANA|^BA', 'ANA|^BAN', 'NA|^BANA',\n",
    "    'A|^BANAN', '|^BANANA']\n",
    "    >>> all_rotations(\"a_asa_da_casa\") # doctest: +NORMALIZE_WHITESPACE\n",
    "    ['a_asa_da_casa', '_asa_da_casaa', 'asa_da_casaa_', 'sa_da_casaa_a',\n",
    "    'a_da_casaa_as', '_da_casaa_asa', 'da_casaa_asa_', 'a_casaa_asa_d',\n",
    "    '_casaa_asa_da', 'casaa_asa_da_', 'asaa_asa_da_c', 'saa_asa_da_ca',\n",
    "    'aa_asa_da_cas']\n",
    "    >>> all_rotations(\"panamabanana\") # doctest: +NORMALIZE_WHITESPACE\n",
    "    ['panamabanana', 'anamabananap', 'namabananapa', 'amabananapan',\n",
    "    'mabananapana', 'abananapanam', 'bananapanama', 'ananapanamab',\n",
    "    'nanapanamaba', 'anapanamaban', 'napanamabana', 'apanamabanan']\n",
    "    >>> all_rotations(5)\n",
    "    Traceback (most recent call last):\n",
    "        ...\n",
    "    TypeError: The parameter s type must be str.\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        raise TypeError(\"The parameter s type must be str.\")\n",
    "\n",
    "    return [s[i:] + s[:i] for i in range(len(s))]\n",
    "\n",
    "#print(all_rotations(\"ATTACA\"))\n",
    "\n",
    "\n",
    "def bwt_transform(s: str) -> dict:\n",
    "    \"\"\"\n",
    "    :param s: The string that will be used at bwt algorithm\n",
    "    :return: the string composed of the last char of each row of the ordered\n",
    "    rotations and the index of the original string at ordered rotations list\n",
    "    :raises TypeError: If the s parameter type is not str\n",
    "    :raises ValueError: If the s parameter is empty\n",
    "    Examples:\n",
    "\n",
    "    >>> bwt_transform(\"^BANANA\")\n",
    "    {'bwt_string': 'BNN^AAA', 'idx_original_string': 6}\n",
    "    >>> bwt_transform(\"a_asa_da_casa\")\n",
    "    {'bwt_string': 'aaaadss_c__aa', 'idx_original_string': 3}\n",
    "    >>> bwt_transform(\"panamabanana\")\n",
    "    {'bwt_string': 'mnpbnnaaaaaa', 'idx_original_string': 11}\n",
    "    >>> bwt_transform(4)\n",
    "    Traceback (most recent call last):\n",
    "        ...\n",
    "    TypeError: The parameter s type must be str.\n",
    "    >>> bwt_transform('')\n",
    "    Traceback (most recent call last):\n",
    "        ...\n",
    "    ValueError: The parameter s must not be empty.\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        raise TypeError(\"The parameter s type must be str.\")\n",
    "    if not s:\n",
    "        raise ValueError(\"The parameter s must not be empty.\")\n",
    "\n",
    "    rotations = all_rotations(s)\n",
    "    rotations.sort()  # sort the list of rotations in alphabetically order\n",
    "    # make a string composed of the last char of each rotation\n",
    "    return {\n",
    "        \"bwt_string\": \"\".join([word[-1] for word in rotations]),\n",
    "        \"idx_original_string\": rotations.index(s),\n",
    "        \"bwt_firstcol\":\"\".join([word[0] for word in rotations])\n",
    "    }\n",
    "\n",
    "\n",
    "#test_str = \"abracadabra$\"\n",
    "#print(bwt_transform(test_str))\n",
    "\n",
    "\n",
    "def reverse_bwt(bwt_string: str, idx_original_string: int) -> str:\n",
    "    \"\"\"\n",
    "    :param bwt_string: The string returned from bwt algorithm execution\n",
    "    :param idx_original_string: A 0-based index of the string that was used to\n",
    "    generate bwt_string at ordered rotations list\n",
    "    :return: The string used to generate bwt_string when bwt was executed\n",
    "    :raises TypeError: If the bwt_string parameter type is not str\n",
    "    :raises ValueError: If the bwt_string parameter is empty\n",
    "    :raises TypeError: If the idx_original_string type is not int or if not\n",
    "    possible to cast it to int\n",
    "    :raises ValueError: If the idx_original_string value is lower than 0 or\n",
    "    greater than len(bwt_string) - 1\n",
    "\n",
    "    >>> reverse_bwt(\"BNN^AAA\", 6)\n",
    "    '^BANANA'\n",
    "    >>> reverse_bwt(\"aaaadss_c__aa\", 3)\n",
    "    'a_asa_da_casa'\n",
    "    >>> reverse_bwt(\"mnpbnnaaaaaa\", 11)\n",
    "    'panamabanana'\n",
    "    >>> reverse_bwt(4, 11)\n",
    "    Traceback (most recent call last):\n",
    "        ...\n",
    "    TypeError: The parameter bwt_string type must be str.\n",
    "    >>> reverse_bwt(\"\", 11)\n",
    "    Traceback (most recent call last):\n",
    "        ...\n",
    "    ValueError: The parameter bwt_string must not be empty.\n",
    "    >>> reverse_bwt(\"mnpbnnaaaaaa\", \"asd\") # doctest: +NORMALIZE_WHITESPACE\n",
    "    Traceback (most recent call last):\n",
    "        ...\n",
    "    TypeError: The parameter idx_original_string type must be int or passive\n",
    "    of cast to int.\n",
    "    >>> reverse_bwt(\"mnpbnnaaaaaa\", -1)\n",
    "    Traceback (most recent call last):\n",
    "        ...\n",
    "    ValueError: The parameter idx_original_string must not be lower than 0.\n",
    "    >>> reverse_bwt(\"mnpbnnaaaaaa\", 12) # doctest: +NORMALIZE_WHITESPACE\n",
    "    Traceback (most recent call last):\n",
    "        ...\n",
    "    ValueError: The parameter idx_original_string must be lower than\n",
    "    len(bwt_string).\n",
    "    >>> reverse_bwt(\"mnpbnnaaaaaa\", 11.0)\n",
    "    'panamabanana'\n",
    "    >>> reverse_bwt(\"mnpbnnaaaaaa\", 11.4)\n",
    "    'panamabanana'\n",
    "    \"\"\"\n",
    "    if not isinstance(bwt_string, str):\n",
    "        raise TypeError(\"The parameter bwt_string type must be str.\")\n",
    "    if not bwt_string:\n",
    "        raise ValueError(\"The parameter bwt_string must not be empty.\")\n",
    "    try:\n",
    "        idx_original_string = int(idx_original_string)\n",
    "    except ValueError:\n",
    "        raise TypeError(\n",
    "            \"The parameter idx_original_string type must be int or passive\"\n",
    "            \" of cast to int.\"\n",
    "        )\n",
    "    if idx_original_string < 0:\n",
    "        raise ValueError(\"The parameter idx_original_string must not be lower than 0.\")\n",
    "    if idx_original_string >= len(bwt_string):\n",
    "        raise ValueError(\n",
    "            \"The parameter idx_original_string must be lower than\" \" len(bwt_string).\"\n",
    "        )\n",
    "\n",
    "    ordered_rotations = [\"\"] * len(bwt_string)\n",
    "    for x in range(len(bwt_string)):\n",
    "        for i in range(len(bwt_string)):\n",
    "            ordered_rotations[i] = bwt_string[i] + ordered_rotations[i]\n",
    "        ordered_rotations.sort()\n",
    "    return ordered_rotations[idx_original_string]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My attempt at FM_index<br>  \n",
    "naiive, store BWT->original string L mapping every index instead of every N indexes  <br>\n",
    "\n",
    "\n",
    "implements traceback<br>  \n",
    "definitely not efficient:<br>  \n",
    "<t>    calculates bwt based on rotations, can do it faster<br> \n",
    "    big size complexity, several arrays that scale with size N<br> \n",
    "    stores all rotations in memory O(n^2) at the start<br>  \n",
    "        bwt string, size n<br>  \n",
    "        occurrences array, size 4n<br>  \n",
    "        counts array, size 4<br>  \n",
    "    big time complexity,<br>  \n",
    "        getting rotations, O(n)<br>  \n",
    "        have to sort rotations, quicksort, O(n log n)<br>  \n",
    "        populating occurrences, counts array, O(n)<br>  \n",
    "        \n",
    "Functions:<br>\n",
    "    all_rotations_sa()<\\br><br>\n",
    "    gets all the rotations of the string L<br>\n",
    "    bwt_sa()<br>\n",
    "        calls all_rotations_sa()\n",
    "        uses the rotations to a dictionary with 2 objects:\n",
    "            'bwt_string', the bwt transform in string form\n",
    "            'bwt_pos', bwt->original string mapping, as a string of integers\n",
    "    all_rotations_fm()\n",
    "        constructs the actual fm_index<br>\n",
    "        calls bwt_sa() to get the bwt<br>\n",
    "        returns a tuple:<br>\n",
    "            test_str_bwt, the bwt dictionary in bwt_sa()<br>\n",
    "            occurrences, 5xn matrix containing the cumulative occurrences of each symbol<br>\n",
    "                used in backtrack()<br>\n",
    "            lexically_smaller, a dictionary with each value being the number of symbols lexically smaller<br>\n",
    "                used in backtrack()<br>\n",
    "            counts, the counts of each symbol<br>\n",
    "                used in find_pattern()<br>\n",
    "\n",
    "    backtrack()\n",
    "        given a pos in the bwt, finds the symbol previous\n",
    "        returns previous_pos,previous_symbol\n",
    "            the position and symbol of the previous element in the bwt\n",
    "    find_pattern()\n",
    "        given a pattern and a bwt, find all found positions of the pattern in the bwt\n",
    "        algorithm:\n",
    "            initializes an array of potential matches, iterate through the bwt to find the last char in the pattern\n",
    "            for each potential match:\n",
    "                call back_track() until you get a match\n",
    "                if you get a match, append it to an array\n",
    "                else break and go to the next match\n",
    "            returns all the matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#My attempt at FM_index\n",
    "#naiive, store BWT->original string L mapping every index instead of every N indexes\n",
    "#implements traceback\n",
    "#definitely not efficient:\n",
    "    #calculates bwt based on rotations, can do it faster\n",
    "    #big size complexity, several arrays that scale with size N\n",
    "        #stores all rotations in memory O(n^2) at the start\n",
    "        #bwt string, size n\n",
    "        #occurrences array, size 4n\n",
    "        #counts array, size 4\n",
    "    #big time complexity,\n",
    "        #getting rotations, O(n)\n",
    "        #have to sort rotations, quicksort, O(n log n)\n",
    "        #populating occurrences, counts array, O(n)\n",
    "        #\n",
    "\n",
    "\n",
    "'''References\n",
    "https://en.wikipedia.org/wiki/FM-index\n",
    "http://bowtie-bio.sourceforge.net/index.shtml\n",
    "https://python.algorithms-library.com/compression/burrows_wheeler, for the above bwt (inefficient rotations version)\n",
    "'''\n",
    "\n",
    "#constructing fm index\n",
    "#constructing C(c) lexically smaller table, counts the number of characters that are lexically smaller\n",
    "    # \" for each character c in the alphabet, \n",
    "    # contains the number of occurrences of \n",
    "    # lexically smaller characters in the text.\"\n",
    "    # in this case, just counting the occurences of each base\n",
    "\n",
    "#constructing Occ(c, k) occurrence table,\n",
    "    #\n",
    "\n",
    "#constructing both tables while using modified rotations function\n",
    "\n",
    "A = 0\n",
    "C = 1\n",
    "G = 2\n",
    "T = 3\n",
    "\n",
    "#gets all the rotations of the string\n",
    "#the first rotation ending with $ is always mapped to the end\n",
    "def all_rotations_sa(s:str):\n",
    "    ret = [((s[0:]+s[:0]),len(s)-1)] #mapped to the end\n",
    "    for i in range(1,len(s)):\n",
    "        ret.append(((s[i:] + s[:i]),i-1))\n",
    "    #print(ret)\n",
    "    return ret\n",
    "    #return [((s[i:] + s[:i]),i) for i in range(start=1,stop=len(s))]\n",
    "\n",
    "\n",
    "#calculates bwt of the s using rotations\n",
    "def bwt_sa(s:str):\n",
    "    rotations = all_rotations_sa(s)\n",
    "    rotations.sort()  # sort the list of rotations in alphabetically order\n",
    "    # make a string composed of the last char of each rotation\n",
    "\n",
    "    bwt_string = \"\"\n",
    "    positions = []\n",
    "    for word,pos in rotations:\n",
    "        bwt_string+= (word[-1])\n",
    "        positions.append(pos)\n",
    "\n",
    "    return { #\"idx_original_string\": rotations.index(s),\n",
    "        \"bwt_string\": bwt_string,\n",
    "        \n",
    "        \"bwt_pos\":positions\n",
    "    }\n",
    "\n",
    "#calculate fm index\n",
    "def all_rotations_fm(l:str ):\n",
    "    if not isinstance(l, str):\n",
    "        raise TypeError(\"The parameter s type must be str.\")\n",
    "\n",
    "    len_l = len(l)\n",
    "    rotations = []\n",
    "    counts = {'$':0,'A':0,'C':0,'G':0,'T':0}\n",
    "    occurrences = {'$':[0]*len_l,'A':[0]*len_l,'C':[0]*len_l,'G':[0]*len_l,'T':[0]*len_l,}\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(all_rotations(test_str))\n",
    "    \n",
    "    test_str_bwt = (bwt_sa(l))\n",
    "    \n",
    "\n",
    "    #calculate rotations and get the bwt\n",
    "    s = test_str_bwt['bwt_string']\n",
    "\n",
    "    s_map = []#mapping bwt to the original string s\n",
    "\n",
    "    #iterate through the bwt\n",
    "    for i,symbol in zip(range(len_l),s):\n",
    "        rotations.append(s[i:]+s[:i])\n",
    "        counts[symbol]+=1\n",
    "\n",
    "\n",
    "        occurrences['A'][i] = occurrences['A'][i-1]\n",
    "        occurrences['C'][i] = occurrences['C'][i-1]\n",
    "        occurrences['G'][i] = occurrences['G'][i-1]\n",
    "        occurrences['T'][i] = occurrences['T'][i-1]\n",
    "        occurrences['$'][i] = occurrences['$'][i-1]\n",
    "        occurrences[symbol][i]+=1\n",
    "        #print(occurrences[symbol][i])\n",
    "\n",
    "    #print(counts)\n",
    "\n",
    "\n",
    "    lexically_smaller = {'$':0,'A':0,'C':0,'G':0,'T':0}\n",
    "    lexically_smaller['A'] = counts['$']\n",
    "    lexically_smaller['C'] = counts['A'] + lexically_smaller['A']\n",
    "    lexically_smaller['G'] = counts['C'] + lexically_smaller['C']\n",
    "    lexically_smaller['T'] = counts['G'] + lexically_smaller['G']\n",
    "\n",
    "    #print(occurrences)\n",
    "    #print(lexically_smaller)\n",
    "\n",
    "    return test_str_bwt,occurrences,lexically_smaller,counts\n",
    "    #return [s[i:] + s[:i] for i in range(len(s))]\n",
    "\n",
    "fm_index = all_rotations_fm(\"AAACGT$\")\n",
    "\n",
    "#last to first mapping?\n",
    "#ideally linear time, realistically dont know\n",
    "LEXICALLY_SMALLER = 2\n",
    "OCCURRENCES = 1\n",
    "def backtrack(fm_index,pos):\n",
    "    #returns the symbol before in the sequence\n",
    "     #index starts at 1\n",
    "\n",
    "    bwt_transform  = fm_index[0]['bwt_string']\n",
    "    #print(\"bwt_transform,\",bwt_transform)\n",
    "\n",
    "    symbol_at_pos = bwt_transform[pos]\n",
    "    \n",
    "\n",
    "    #lexically smaller and occurrences\n",
    "    previous_pos = fm_index[LEXICALLY_SMALLER][symbol_at_pos]+fm_index[OCCURRENCES][symbol_at_pos][pos]-1\n",
    "    previous_symbol = bwt_transform[previous_pos]\n",
    "    #print(symbol_at_pos, pos,\"|previous:\",previous_symbol,previous_pos)\n",
    "\n",
    "    return previous_symbol,previous_pos\n",
    "backtrack(fm_index,0)\n",
    "\n",
    "\n",
    "'''\n",
    "count_keys = iter(fm_index[2])\n",
    "for key in count_keys:\n",
    "    print(key)'''\n",
    "\n",
    "BWT = 0\n",
    "COUNTS = 3\n",
    "\n",
    "SYMBOL = 0\n",
    "POS = 1\n",
    "def find_pattern(pattern,fm_index):\n",
    "    \n",
    "    last_char = pattern[-1]\n",
    "\n",
    "\n",
    "    num_potential_matches= fm_index[COUNTS][last_char]\n",
    "    #print(\"number of potential matches:\" ,num_potential_matches)\n",
    "    \n",
    "    match_arr = [0] * num_potential_matches\n",
    "    target_char = last_char\n",
    "    i = 0\n",
    "    match_no = 0\n",
    "\n",
    "    #initialize match_arr\n",
    "    for symbol in fm_index[BWT]['bwt_string']:\n",
    "        if(symbol == target_char):\n",
    "            match_arr[match_no] = i\n",
    "            match_no+=1\n",
    "\n",
    "        i+=1\n",
    "    pattern = pattern[:-1]\n",
    "    #print(\"pattern\",pattern)\n",
    "\n",
    "    #print(\"match_arr:\",match_arr)\n",
    "\n",
    "    #find rest of matches\n",
    "    #get first match\n",
    "\n",
    "    #print('------------')\n",
    "    \n",
    "    len_pattern = len(pattern)\n",
    "\n",
    "    match_no = 0\n",
    "    target_pattern = pattern\n",
    "    found_patterns = []\n",
    "    for match in match_arr:\n",
    "        for i in range(len_pattern):\n",
    "            #print(pattern)\n",
    "            target_char = pattern[-1]\n",
    "            prev_char,pos = backtrack(fm_index,match)\n",
    "            if prev_char != target_char:\n",
    "                #print(\"no match\")\n",
    "                match = None\n",
    "                break\n",
    "            match = pos\n",
    "            pattern = pattern[:-1]\n",
    "        if match:\n",
    "            #print(\"match: pos+i\",match,len_pattern,match+len_pattern)\n",
    "\n",
    "            found_patterns.append(match) #start of pattern\n",
    "            #found_patterns.append(match+len_pattern) #end of pattern\n",
    "            \n",
    "\n",
    "        #reset variables\n",
    "        pattern = target_pattern\n",
    "\n",
    "\n",
    "        #pattern = pattern[:-1]\n",
    "    #print(\"found patterns in bwt: \", found_patterns)\n",
    "    return found_patterns\n",
    "\n",
    "\n",
    "#bwt->original string l mapping, stored as bwt_pos, initialized in all_positions_sa()\n",
    "class bwt_naiive:\n",
    "    def __init__(self,contig):\n",
    "        self.fm_index = all_rotations_fm(contig)\n",
    "\n",
    "    #given bwt_pos, find l_pos\n",
    "    def locate(self,pos):\n",
    "        return self.fm_index[0]['bwt_pos'][pos]\n",
    "\n",
    "\n",
    "#testing!\n",
    "'''\n",
    "l = \"AAACCCGGGTTT$\"\n",
    "naiive_test = bwt_naiive(l)\n",
    "print(\"l: \",l)\n",
    "print(\"bwt_str: \", naiive_test.fm_index[0]['bwt_string'])\n",
    "print(\"bwt_pos\",naiive_test.fm_index[0]['bwt_pos'])\n",
    "print(\"pos of $\",naiive_test.locate(1))\n",
    "print(\"all rotations: \",all_rotations_sa(l))\n",
    "    \n",
    "\n",
    "\n",
    "pos = find_pattern(\"AAA\",naiive_test.fm_index)[0]\n",
    "\n",
    "pos = 2\n",
    "\n",
    "#testing bwt->l mapping\n",
    "#for pos in range(len(l)):\n",
    "l_pos = naiive_test.locate(pos)\n",
    "print(\"pos in bwt\",pos,naiive_test.fm_index[0]['bwt_string'][pos])\n",
    "print(\"pos in l\",l_pos,l[l_pos])\n",
    "'''\n",
    "a = 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Driver Function\n",
    "Working around memory limitations!\n",
    "\n",
    "Problem:\n",
    "naiive BWT takes n^2 memory to store and sort initially\n",
    "\n",
    "Solution:\n",
    "break the genome into reasonable chunks, 10,000 bp per chunk\n",
    "construct the bwt and do all pattern matches on that chunk's bwt\n",
    "repeat until entire genome is covered\n",
    "Cheat and sort the reads?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('contig1', 1987, 'CACCTTGGAGGATTTGCCGGTTTGAGATCCTTGCATGGTCATCTGTAAAAAATTCACTACTAGCATTATCGCTAACGTCTCAAATAAAGTCGCCAATGGC')\n",
      "('contig1', 8096, 'GGGGCCCAGAGGCTTTACTGGTCTAGGTTTTATTAAATTTCAAAATTGCCAATTCCAGACGGGAATCGTCTCGACACGATTCCCAAGGCTCTCGTTGCTT')\n"
     ]
    }
   ],
   "source": [
    "#parse input reads\n",
    "\n",
    "reads = []\n",
    "with open(\"cs144part1_1000.txt\",'r') as file:\n",
    "    \n",
    "    while True:\n",
    "        header = file.readline()\n",
    "        if not header:\n",
    "            break\n",
    "        header = header.split(',')\n",
    "        contig = header[0][1:]\n",
    "        pos = int(header[1][:-1])\n",
    "        \n",
    "        #contig = contig[:-1]#cull the newline\n",
    "        \n",
    "        read = file.readline()\n",
    "        read = read[:-1] #cull the newline\n",
    "        reads.append((contig,pos,read))\n",
    "print(reads[0])\n",
    "print(reads[1])\n",
    "#reads = reads[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L: 100\n",
      "read length:  1000\n",
      "found reads length: 181\n",
      "number of correct reads: 167\n"
     ]
    }
   ],
   "source": [
    "#Driver Function\n",
    "class read_mapper():\n",
    "    def __init__(self,l:str):\n",
    "        \n",
    "        self.bwt_l = bwt_naiive(l)\n",
    "    def read_mapping(self,pattern:str): #look for a pattern in the contig substr\n",
    "        pattern_locations = find_pattern(pattern,self.bwt_l.fm_index)\n",
    "        if pattern_locations:\n",
    "            for start in pattern_locations:\n",
    "                found_pos = self.bwt_l.locate(start)\n",
    "                #l_substr = l[found_pos:found_pos+len(pattern)]+\"|\"+l[found_pos+len(pattern):found_pos+len(pattern)+10]\n",
    "\n",
    "                \n",
    "                #print(\"found pattern at \",found_pos)\n",
    "                #print(\"l representation:\",l_substr)\n",
    "                \n",
    "            return pattern_locations\n",
    "        else:\n",
    "            return []\n",
    "        \n",
    "\n",
    "#Open fasta to read\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "file = open(\"cs144input.txt\")\n",
    "input = str(file.read())\n",
    "\n",
    "print(\"L:\",L)\n",
    "print(\"read length: \",len(reads))\n",
    "file.close()\n",
    "\n",
    "fasta_index = seq.index(\"./BD.fasta\", \"fasta\")\n",
    "\n",
    "record_ids = []\n",
    "for record_id in fasta_index:\n",
    "    record_ids.append(record_id)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#first_chunk = str(fasta_index[record_ids[0]].seq[90000:90000+chunk_length])\n",
    "pattern = \"AAAATGTCAATTATAAATGACATTGACAAGTACATTATAGCAACACGTCGCGATGCTACTGGAGACTATAGTAATGTTTTACCAATTGATAAAATTGGTC\"\n",
    "patterns = []\n",
    "length_patterns = 1\n",
    "for i in range(length_patterns):\n",
    "    patterns.append(pattern)\n",
    "\n",
    "\n",
    "#first_chunk_bwt = read_mapper(first_chunk)\n",
    "#first_chunk_bwt.read_mapping(pattern)\n",
    "\n",
    "pos = 0 #starting pos\n",
    "chunk_length = 10000# ~amount of memory possible with naiive bwt, best time is about .7s to index 10,000\n",
    "seq_length = len(fasta_index[record_ids[0]].seq) #search in first contig\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "mapped_reads = []\n",
    "correct_reads = 0\n",
    "while(pos < seq_length): #search through only first contig\n",
    "    #print(pos)\n",
    "    next_chunk = str(fasta_index[record_ids[0]].seq[pos:pos+chunk_length]) \n",
    "    chunk_bwt = read_mapper(next_chunk)\n",
    "\n",
    "    for contig,read_pos,pattern in reads: #read\n",
    "        \n",
    "        matches = chunk_bwt.read_mapping(pattern)\n",
    "        for match in matches:\n",
    "            chunk_pos = chunk_bwt.bwt_l.locate(match)\n",
    "            chunk_pos += pos #add the current position in the contig with chunk_pos\n",
    "            #print(\"location: \",chunk_pos)\n",
    "            #print(\"readpos vs chunkpos: \",read_pos,chunk_pos)\n",
    "            if(chunk_pos == read_pos):\n",
    "                correct_reads+=1\n",
    "            mapped_reads.append((contig,chunk_pos,pattern))\n",
    "\n",
    "    pos = pos-L+chunk_length #chunk always has an additional L to catch missed sequences\n",
    "\n",
    "print(\"found reads length:\",len(mapped_reads))\n",
    "print(\"number of correct reads:\",correct_reads)\n",
    "#print(\"chunk: \",first_chunk)\n",
    "\n",
    "#get a chunk from the genome\n",
    "#do read_mapping on that chunk for a particular pattern\n",
    "    #maybe store the fm_index?\n",
    "#>contig1,93711\n",
    "#AAAATGTCAATTATAAATGACATTGACAAGTACATTATAGCAACACGTCGCGATGCTACTGGAGACTATAGTAATGTTTTACCAATTGATAAAATTGGTC\n",
    "#initial\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#testing\n",
    "#g = \"TTCATCGAACATCCGTAAAAATGGCGTTTTGTTTTTGCCGCTGCATGATGATACGAGATCGTCGCAACAATGGAATTGTGAATCGTGCATTCCCTGCCTA$\"\n",
    "#pattern = input[:100]\n",
    "#l = input+'$\n",
    "#read_mapping(l,pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L: 100\n",
    "read length:  1000\n",
    "found reads length: 181\n",
    "number of correct reads: 167\n",
    "18m48s"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0944f6eb843faf35791b135d90ecc01e87181702fe44fe51adb8b690e842506a"
  },
  "kernelspec": {
   "display_name": "Python 3.6.4 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
